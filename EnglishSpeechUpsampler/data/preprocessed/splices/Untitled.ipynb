{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def decode_csv(line):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    Line : Line item from a csv file\n",
    "    Returns:\n",
    "    A parsed csv line \n",
    "    \"\"\"\n",
    "    parsed_line = tf.decode_csv(line, [['string'], ['string']])\n",
    "    return parsed_line\n",
    "\n",
    "\n",
    "def audiofile_to_input_vector(truth_file, ds_file):\n",
    "    \"\"\"\n",
    "    Calculates a feature vector given a filename\n",
    "\n",
    "    Args:\n",
    "    audio_filename : Name of the audio file in wav format\n",
    "    numcep : Number of cepstral coeffs to return\n",
    "\n",
    "    Returns:\n",
    "    A feature vector of size [num of frames, numcep]\n",
    "    \"\"\"\n",
    "    # Load truth wav files\n",
    "    binary_truth = file_io.FileIO(truth_file, 'r')\n",
    "    fs_truth, audio_truth = wav.read(binary)\n",
    "    \n",
    "    # Load downsampled wav files\n",
    "    binary_ds = file_io.FileIO(truth_file, 'r')\n",
    "    fs_ds, audio_ds = wav.read(binary)\n",
    "    \n",
    "    return [truth_audio, ds_audio]\n",
    "\n",
    "\n",
    "def input_parser(truth_file, ds_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function for feature extraction in tensorflow\n",
    "    \"\"\"\n",
    "\n",
    "    audio_numpy = tf.py_func(audiofile_to_input_vector,[truth_file,ds_file],  [tf.float32])\n",
    "\n",
    "\n",
    "\n",
    "def train_input(data_filepath, batch_size,\n",
    "                num_epoch):\n",
    "    \"\"\"\n",
    "    Function to create batches for inference using Tensorflow\n",
    "    \"\"\"\n",
    "#     dataset = tf.data.TextLineDataset(data_filepath).map(decode_csv,num_parallel_calls=cpu_count())\n",
    "    dataset = tf.data.TextLineDataset(data_filepath).map(decode_csv)\n",
    "#     dataset = dataset.map(input_parser,num_parallel_calls=cpu_count())\n",
    "    dataset = dataset.map(input_parser)\n",
    "    dataset = dataset.apply(tf.contrib.data.ignore_errors())\n",
    "    dataset = dataset.repeat(num_epoch)\n",
    "#     dataset = dataset.padded_batch(batch_size,\n",
    "#                                  padded_shapes=([None, 26],[]))\n",
    "    dataset = dataset.prefetch(2)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_feats, batch_lens = iterator.get_next()\n",
    "    return batch_feats, batch_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mohit/Desktop/Research papers/Implementation/EnglishSpeechUpsampler/data/preprocessed/test_files.csv'\n",
    "train_input(path, 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-56d97f45cce6>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-56d97f45cce6>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    dataset = dataset.padded_batch(batch_size, padded_shapes=([],[],[,None],[]))\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def decode_csv(line):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    Line : Line item from a csv file\n",
    "    Returns:\n",
    "    A parsed csv line \n",
    "    \"\"\"\n",
    "    parsed_line = tf.decode_csv(line, [['string'], ['string']])\n",
    "    return parsed_line[0]\n",
    "\n",
    "\n",
    "def audiofile_to_input_vector(truth_file):\n",
    "    \"\"\"\n",
    "    Calculates a feature vector given a filename\n",
    "\n",
    "    Args:\n",
    "    audio_filename : Name of the audio file in wav format\n",
    "    numcep : Number of cepstral coeffs to return\n",
    "\n",
    "    Returns:\n",
    "    A feature vector of size [num of frames, numcep]\n",
    "    \"\"\"\n",
    "    # Load truth wav files\n",
    "    binary_truth = file_io.FileIO(truth_file, 'r')\n",
    "    fs_truth, audio_truth = wav.read(binary)\n",
    "    print(tf.size(audio_truth))\n",
    "    \n",
    "    return audio_truth\n",
    "\n",
    "\n",
    "def input_parser(truth_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function for feature extraction in tensorflow\n",
    "    \"\"\"\n",
    "    audio_array = tf.py_func(audiofile_to_input_vector,[truth_file], [tf.float32])\n",
    "    print('Details:',audio_array[0].shape, type(audio_array))\n",
    "#     with tf.Session() as sess2:\n",
    "#         print('Audio array is: ',audio_array[0].eval())\n",
    "    return audio_array\n",
    "\n",
    "\n",
    "def train_input(data_filepath, batch_size, num_epoch):\n",
    "    \"\"\"\n",
    "    Function to create batches for inference using Tensorflow\n",
    "    \"\"\"\n",
    "#     dataset = tf.data.TextLineDataset(data_filepath).map(decode_csv,num_parallel_calls=cpu_count())\n",
    "    dataset = tf.data.TextLineDataset(data_filepath).map(decode_csv)\n",
    "#     dataset = dataset.map(input_parser,num_parallel_calls=cpu_count())\n",
    "\n",
    "    dataset = dataset.map(input_parser)\n",
    "    dataset = dataset.apply(tf.contrib.data.ignore_errors())\n",
    "    dataset = dataset.repeat(num_epoch)\n",
    "    # How to pad file\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=([],[],[,None],[]))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_feats = iterator.get_next()\n",
    "    print(type(batch_feats))\n",
    "    return batch_feats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details: <unknown> <class 'list'>\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext_1:0' shape=<unknown> dtype=float32>,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/mohit/Desktop/Research papers/Implementation/EnglishSpeechUpsampler/data/preprocessed/test_files.csv'\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(train_input(path, 2,3)))\n",
    "    \n",
    "train_input(path, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
