{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "from inputs import get_bit_rates_and_waveforms\n",
    "from inputs import randomly_batch, next_batch\n",
    "from inputs import read_file_pair, get_truth_ds_filename_pairs\n",
    "import tensorflow as tf\n",
    "from models import deep_residual_network\n",
    "from losses import mse\n",
    "from optimizers import make_variable_learning_rate, setup_optimizer\n",
    "import down_up_sample_main\n",
    "from optimizers import make_variable_learning_rate, setup_optimizer\n",
    "\n",
    "data_settings_file = 'settings/data_settings.json'\n",
    "training_settings_file = 'settings/training_settings.json'\n",
    "model_settings_file = 'settings/model_settings.json'\n",
    "\n",
    "data_settings = json.load(open(data_settings_file))\n",
    "training_settings = json.load(open(training_settings_file))\n",
    "model_settings = json.load(open(model_settings_file))\n",
    "\n",
    "# Constants describing the training process.\n",
    "# Samples per batch.\n",
    "BATCH_SIZE = training_settings['batch_size']\n",
    "# Number of epochs to train.\n",
    "NUMBER_OF_EPOCHS = training_settings['number_of_epochs']\n",
    "# Epochs after which learning rate decays.\n",
    "NUM_EPOCHS_PER_DECAY = training_settings['num_epochs_per_decay']\n",
    "# Learning rate decay factor.\n",
    "LEARNING_RATE_DECAY_FACTOR = training_settings['learning_rate_decay_factor']\n",
    "# Initial learning rate.\n",
    "INITIAL_LEARNING_RATE = training_settings['initial_learning_rate']\n",
    "\n",
    "example_number = 0\n",
    "write_tb = False\n",
    "file_name_lists_dir = data_settings['output_dir_name_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:1\", shape=(?, 16000, 1), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 16000, 1), dtype=float32, device=/device:CPU:0)\n",
      " data pipeline setup \n",
      "1\n",
      "layer summary for deep_residual network\n",
      "input: [None, 16000, 1]\n",
      "input: [16000, 1]\n",
      "input_tensor.get_shape().as_list()[-1]1\n",
      "downsample layer: [7998, 8]\n",
      "input_tensor.get_shape().as_list()[-1]8\n",
      "downsample layer: [3998, 16]\n",
      "input_tensor.get_shape().as_list()[-1]16\n",
      "downsample layer: [1998, 32]\n",
      "input_tensor.get_shape().as_list()[-1]32\n",
      "downsample layer: [998, 64]\n",
      "input_tensor.get_shape().as_list()[-1]64\n",
      "downsample layer: [498, 128]\n",
      "input_tensor.get_shape().as_list()[-1]128\n",
      "downsample layer: [248, 256]\n",
      "input_tensor.get_shape().as_list()[-1]256\n",
      "downsample layer: [123, 512]\n",
      "input_tensor.get_shape().as_list()[-1]512\n",
      "downsample layer: [61, 1024]\n",
      "input_tensor.get_shape().as_list()[-1]1024\n",
      "bottleneck layer: [29, 2048]\n",
      "upsample layer: [54, 2048]\n",
      "upsample layer: [104, 1024]\n",
      "upsample layer: [204, 512]\n",
      "upsample layer: [404, 256]\n",
      "upsample layer: [804, 128]\n",
      "upsample layer: [1604, 64]\n",
      "upsample layer: [3204, 32]\n",
      "upsample layer: [6404, 16]\n",
      "restack layer: [8002, 12]\n",
      "final conv layer: [8000, 2]\n",
      "output: [16000, 1]\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "up_audioTensor(\"Shape:0\", shape=(3,), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32, device=/device:CPU:0)\n",
      "tf.shape(up_audio_return_y Tensor(\"Shape_2:0\", shape=(3,), dtype=int32, device=/device:CPU:0)\n",
      "tf.shape(up_audio) Tensor(\"Shape_3:0\", shape=(3,), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"loss/Mean:0\", shape=(), dtype=float32, device=/device:CPU:0)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "0-th value returned by pyfunc_8 is int16, but expects float\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_FLOAT], token=\"pyfunc_8\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,16000,1], [?,16000,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 0-th value returned by pyfunc_8 is int16, but expects float\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_FLOAT], token=\"pyfunc_8\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,16000,1], [?,16000,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52a922dfecd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m            \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m            \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 0-th value returned by pyfunc_8 is int16, but expects float\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_FLOAT], token=\"pyfunc_8\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,16000,1], [?,16000,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]"
     ]
    }
   ],
   "source": [
    " #### my code #### \n",
    "data_filepath =  './data/preprocessed/upsampling.csv'\n",
    "batch_size = 1\n",
    "num_epoch = 1\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            up_audio , down_audio = down_up_sample_main.train_input( data_filepath, batch_size, num_epoch )\n",
    "\n",
    "            print('Down audio', down_audio )\n",
    "            print('Upp audio', up_audio )\n",
    "            print(\" data pipeline setup \")\n",
    "            print( 'Up audio shape',   up_audio.get_shape().as_list()[-1]  ) \n",
    "            #           print( tf.shape( up_audio ).as_list()  )\n",
    "            #           print(  sess.run( tf.shape( up_audio )[-1] ) )\n",
    "            #           print(  sess.run( tf.shape( up_audio )[1:] ) )\n",
    "\n",
    "\n",
    "            #         input_tensor.get_shape().as_list()[-1]\n",
    "            train_flag, x , up_audio_return_y = down_up_sample_main.inference( input_data = up_audio , input_shape = [  16000,1 ] )\n",
    "\n",
    "            #           print( up_audio_return_y )   \n",
    "            print( type(up_audio_return_y) )\n",
    "            print(\"up_audio\"+str( tf.shape(up_audio) ) )\n",
    "            print( tf.shape(up_audio_return_y) )\n",
    "            up_audio_return_y = tf.cast( up_audio_return_y , tf.float32 )\n",
    "            print(\"tf.shape(up_audio_return_y\",tf.shape(up_audio_return_y)) \n",
    "            up_audio = tf.cast( up_audio , tf.float32 )\n",
    "            print(\"tf.shape(up_audio)\",tf.shape(up_audio) )\n",
    "            #           print( sess.run(up_audio_return_y)) )\n",
    "\n",
    "\n",
    "            #           print( sess.run( up_audio_return_y ) )\n",
    "\n",
    "            #           print( type( up_audio_return_y ) )  \n",
    "            #     # Calculate loss.\n",
    "            loss = down_up_sample_main.mse(\"loss\",up_audio, up_audio_return_y)\n",
    "            print( loss )\n",
    "\n",
    "            #           num_batches_per_epoch = float(SAMPLES_PER_EPOCH)/BATCH_SIZE\n",
    "            #           decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "\n",
    "            #           # Decay the learning rate based on the number of steps.\n",
    "            #           lr, global_step = make_variable_learning_rate(INITIAL_LEARNING_RATE,\n",
    "            #                                                           decay_steps,\n",
    "            #                                                           LEARNING_RATE_DECAY_FACTOR,\n",
    "            #                                                           False)\n",
    "\n",
    "            #           min_args = {'global_step': global_step}\n",
    "\n",
    "            #           train_step = setup_optimizer(lr, loss, tf.train.AdamOptimizer,\n",
    "            #                                          using_batch_norm=True,\n",
    "            #                                          min_args=min_args)\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            loss_value = sess.run([loss])\n",
    "\n",
    "            print( loss_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########\n",
    "# DATA IMPORT\n",
    "# ###########\n",
    "\n",
    "train_truth_ds_pairs = get_truth_ds_filename_pairs(file_name_lists_dir,\n",
    "                                                   'train')\n",
    "val_truth_ds_pairs = get_truth_ds_filename_pairs(file_name_lists_dir,\n",
    "                                                 'validation')\n",
    "\n",
    "br_pairs, wf_pairs = get_bit_rates_and_waveforms(train_truth_ds_pairs[0])\n",
    "true_br = br_pairs[0]\n",
    "true_wf = wf_pairs[0]\n",
    "\n",
    "\n",
    "# reshape for mono waveforms\n",
    "true_wf = true_wf.reshape((-1, 1))\n",
    "\n",
    "print('Bit rate and shape:', true_br, true_wf.shape)\n",
    "\n",
    "SAMPLES_PER_EPOCH = len(train_truth_ds_pairs)\n",
    "print('Number of epochs: {}'.format(NUMBER_OF_EPOCHS))\n",
    "print('Samples per epoch: {}'.format(SAMPLES_PER_EPOCH))\n",
    "print('Batch size: {}'.format(BATCH_SIZE))\n",
    "\n",
    "# ###########\n",
    "# ###########\n",
    "\n",
    "\n",
    "# ################\n",
    "# MODEL DEFINITION\n",
    "# ################\n",
    "\n",
    "train_flag, x, model = deep_residual_network(true_wf.dtype,\n",
    "                                             true_wf.shape,\n",
    "                                             **model_settings)\n",
    "\n",
    "# placeholder for the true waveform\n",
    "y_true = tf.placeholder(true_wf.dtype,\n",
    "                        shape=x.get_shape())\n",
    "\n",
    "# ################\n",
    "# ################\n",
    "\n",
    "\n",
    "# #############\n",
    "# LOSS FUNCTION\n",
    "# #############\n",
    "\n",
    "loss = mse('waveform_loss', y_true, model)\n",
    "\n",
    "# #############\n",
    "# #############\n",
    "\n",
    "\n",
    "# ####################\n",
    "# OPTIMIZATION ROUTINE\n",
    "# ####################\n",
    "\n",
    "# Variable that affect learning rate.\n",
    "num_batches_per_epoch = float(SAMPLES_PER_EPOCH)/BATCH_SIZE\n",
    "decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "# Decay the learning rate based on the number of steps.\n",
    "lr, global_step = make_variable_learning_rate(INITIAL_LEARNING_RATE,\n",
    "                                              decay_steps,\n",
    "                                              LEARNING_RATE_DECAY_FACTOR,\n",
    "                                              False)\n",
    "\n",
    "# lr = 1e-4\n",
    "# min_args = {}\n",
    "min_args = {'global_step': global_step}\n",
    "# tf.train.RMSPropOptimizer, tf.train.GradientDescentOptimizer,\n",
    "# tf.train.AdamOptimizer, tf.train.AdagradOptimizer\n",
    "train_step = setup_optimizer(lr, loss, tf.train.AdamOptimizer,\n",
    "                             using_batch_norm=True,\n",
    "                             min_args=min_args)\n",
    "\n",
    "# ####################\n",
    "# ####################\n",
    "\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# create session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initialize tensorboard file writers\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('aux/tensorboard/overtrain',\n",
    "                                     sess.graph)\n",
    "\n",
    "# initialize the variables for the session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# #############\n",
    "# TRAINING LOOP\n",
    "# #############\n",
    "\n",
    "model_name = model.name.replace('/', '_').replace(':', '_')\n",
    "val_loss_file = open('val_loss.txt', 'w')\n",
    "train_loss_file = open('train_loss.txt', 'w')\n",
    "epoch_scale = int(SAMPLES_PER_EPOCH/BATCH_SIZE)\n",
    "for i in range(NUMBER_OF_EPOCHS*epoch_scale):\n",
    "    is_new_epoch = ((i + 1) % epoch_scale == 0)\n",
    "    if is_new_epoch:\n",
    "        epoch_num = int((i + 1) / epoch_scale)\n",
    "    if is_new_epoch:\n",
    "        print('Calculating validation loss ({} iterations)'.format(\n",
    "            len(val_truth_ds_pairs)/BATCH_SIZE))\n",
    "        total_val_loss = 0\n",
    "        val_count = 0\n",
    "        for pair in next_batch(BATCH_SIZE, val_truth_ds_pairs):\n",
    "            loss_value = sess.run([loss],\n",
    "                                feed_dict={train_flag: False,\n",
    "                                           x: pair[1],\n",
    "                                           y_true: pair[0]}\n",
    "                                )\n",
    "            total_val_loss += np.mean(loss_value)\n",
    "            val_count += 1\n",
    "        loss_value = total_val_loss/val_count\n",
    "        val_loss_file.write('{},{}\\n'.format(epoch_num,\n",
    "                                             loss_value))\n",
    "        print(\"Epoch {}, Val Loss {}\".format(epoch_num, loss_value))\n",
    "    batch = randomly_batch(BATCH_SIZE, train_truth_ds_pairs)\n",
    "    if write_tb:\n",
    "        if is_new_epoch:\n",
    "            summary, _, loss = sess.run([merged, train_step, loss],\n",
    "                                        feed_dict={train_flag: True,\n",
    "                                                   x: batch[1],\n",
    "                                                   y_true: batch[0]})\n",
    "            print(\"Epoch {}, Loss {}\".format(epoch_num, loss))\n",
    "            # train_writer.add_summary(summary, i)\n",
    "            train_loss_file.write('{}, {}\\n'.format(epoch_num, loss))\n",
    "            if epoch_num % 3 == 0:\n",
    "                save_path =\\\n",
    "                    saver.save(sess, \"aux/model_checkpoints/{}_{}.ckpt\".format(\n",
    "                                        model_name, epoch_num))\n",
    "\n",
    "    train_step.run(feed_dict={train_flag: True,\n",
    "                              x: batch[1],\n",
    "                              y_true: batch[0]},\n",
    "                   session=sess)\n",
    "    if (i + 1) % 500 == 0 and not is_new_epoch:\n",
    "        loss_val = np.mean(sess.run([loss],\n",
    "                                feed_dict={train_flag: True,\n",
    "                                           x: batch[1],\n",
    "                                           y_true: batch[0]}))\n",
    "        print(\"Iteration {}, Loss {}\".format(i + 1, loss_val))\n",
    "\n",
    "val_loss_file.close()\n",
    "train_loss_file.close()\n",
    "# Save the variables to disk.\n",
    "save_path = saver.save(sess, \"aux/model_checkpoints/{}_final.ckpt\".format(\n",
    "    model_name))\n",
    "print(\"Model checkpoints will be saved in file: {}\".format(save_path))\n",
    "\n",
    "truth, example = read_file_pair(val_truth_ds_pairs[1])\n",
    "y_reco = model.eval(feed_dict={train_flag: False,\n",
    "                               x: example.reshape(1, -1, 1)},\n",
    "                    session=sess).flatten()\n",
    "\n",
    "#print('difference between truth and example (first 20 elements)')\n",
    "#print(truth.flatten()[:20] - example.flatten()[:20])\n",
    "#print('difference between truth and reconstruction (first 20 elements)')\n",
    "#print(truth.flatten()[:20] - y_reco[:20])\n",
    "\n",
    "#print('writting output audio files')\n",
    "#librosa.output.write_wav('full_train_validation_true.wav',\n",
    "#                         y=truth.flatten(), sr=true_br)\n",
    "#librosa.output.write_wav('full_train_validation_ds.wav',\n",
    "#                         y=example.flatten(), sr=true_br)\n",
    "#librosa.output.write_wav('full_train_validation_reco.wav',\n",
    "#                         y=y_reco, sr=true_br)\n",
    "\n",
    "# #############\n",
    "# #############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
